{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "\n",
    "from comet_ml import Experiment\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from src.dataset import Chaos2DSegmentationDataset, NormalizeInstance, get_image_pair_filepaths\n",
    "from src.models import UNet\n",
    "from src.metrics import dice_loss, dice_score\n",
    "from src.utils import create_canvas\n",
    "from src.train import train_one_epoch, validate\n",
    "import src.config\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 # 0: off, 2: on for all modules\n",
    "# os.chdir('CompositionalNets/')\n",
    "# sys.path.append('/project/6052161/mattlk/workplace/CompNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the below directory depending on where the CHAOS dataset is stored\n",
    "data_dir = src.config.directories['chaos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = Experiment(api_key=\"P5seMqEJjqZ8mDA7QYSuK3yUJ\",\n",
    "#                         project_name=\"chaos-liver-segmentation\",\n",
    "#                         workspace=\"matthew42\", auto_metric_logging=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train U-Net on CHAOS for Liver Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.55 s, sys: 2.2 s, total: 4.75 s\n",
      "Wall time: 5.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size\": 8,\n",
    "    \"split_train_val\": 0.8,\n",
    "    \"epochs\": 125,\n",
    "    \"use_dice_loss\": False,\n",
    "    \"cache\": True,\n",
    "    \"random_seed\": 42,\n",
    "    \"shuffle_data\": True,\n",
    "    \"scheduler\": \"StepLR\",\n",
    "    \"step_size\": 15,\n",
    "    \"gamma\": 0.75,\n",
    "    \"threshold\": 0.75,\n",
    "    'weight_decay': 4e-3\n",
    "}\n",
    "\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if is_cuda_available else \"cpu\")\n",
    "input_images_dtype = torch.double\n",
    "targets_dtype = torch.long\n",
    "\n",
    "cache_input_transform = transforms.Compose([\n",
    "    NormalizeInstance(mean=1.0),\n",
    "    transforms.Lambda(lambda x: x.astype(np.float32)),\n",
    "    transforms.ToTensor(),\n",
    "    Resize((256, 256)),\n",
    "])\n",
    "\n",
    "cache_gt_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    Resize((256, 256)),\n",
    "])\n",
    "\n",
    "input_transform = transforms.Compose([\n",
    "#     transforms.RandomAffine(degrees=5, shear=5),\n",
    "#     transforms.ToTensor()\n",
    "])\n",
    "\n",
    "gt_transform = transforms.Compose([\n",
    "#     transforms.RandomAffine(degrees=5, shear=5),\n",
    "#     transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x*255),\n",
    "    transforms.Lambda(lambda x: x.long()),\n",
    "])\n",
    "\n",
    "# Load data for training and validation\n",
    "image_pair_filepaths = get_image_pair_filepaths(data_dir)[:4]\n",
    "train_filepaths, val_filepaths = train_test_split(image_pair_filepaths,\n",
    "                                                  train_size=params['split_train_val'],\n",
    "                                                  random_state=params['random_seed'],\n",
    "                                                  shuffle=params[\"shuffle_data\"])\n",
    "# train_filepaths, val_filepaths = image_pair_filepaths, image_pair_filepaths\n",
    "\n",
    "train_dataset = Chaos2DSegmentationDataset(train_filepaths, input_transform=input_transform,\n",
    "                                           gt_transform=gt_transform, cache=params['cache'],\n",
    "                                           cache_input_transform=cache_input_transform,\n",
    "                                           cache_gt_transform=cache_gt_transform,\n",
    "                                           device=device)\n",
    "\n",
    "val_dataset = Chaos2DSegmentationDataset(val_filepaths, input_transform=input_transform,\n",
    "                                         gt_transform=gt_transform, cache=params['cache'],\n",
    "                                         cache_input_transform=cache_input_transform,\n",
    "                                         cache_gt_transform=cache_gt_transform,\n",
    "                                         device=device)\n",
    "\n",
    "num_train, num_val = len(train_dataset), len(val_dataset)\n",
    "params['num_samples'] = num_train + num_val\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=params['batch_size'])\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=params['batch_size'])\n",
    "\n",
    "# Instantiate model, optimizer, and criterion\n",
    "torch.cuda.empty_cache()\n",
    "unet = UNet(dice=params['use_dice_loss'])\n",
    "if is_cuda_available: unet = unet.to(device, dtype=input_images_dtype)\n",
    "\n",
    "optimizer = optim.Adam(unet.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "if params['scheduler'] == 'StepLR': \n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                          step_size=params['step_size'], gamma=params['gamma'])\n",
    "elif params['scheduler'] == 'ReduceLROnPlateau':\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# cross-entropy loss: weighting of negative vs positive pixels\n",
    "loss_weight = torch.DoubleTensor([0.01, 0.99])\n",
    "if is_cuda_available: loss_weight = loss_weight.to(device)\n",
    "criterion = dice_loss if params['use_dice_loss'] else CrossEntropyLoss(weight=loss_weight,\n",
    "                                                                       reduction='mean')\n",
    "\n",
    "# experiment.log_parameters(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images:\t3\n",
      "Number of validation images:\t1\n",
      "[Epoch 001 Training]\tCross-Entropy Loss:\t0.0427\n",
      "[Epoch 001 Validation]\tAverage F1 Score:\t1.0000\tAverage Jaccard/IoU:\t1.0000\n",
      "\n",
      "[Epoch 002 Training]\tCross-Entropy Loss:\t0.0394\n",
      "[Epoch 002 Validation]\tAverage F1 Score:\t1.0000\tAverage Jaccard/IoU:\t1.0000\n",
      "\n",
      "[Epoch 003 Training]\tCross-Entropy Loss:\t0.0365\n",
      "[Epoch 003 Validation]\tAverage F1 Score:\t1.0000\tAverage Jaccard/IoU:\t1.0000\n",
      "\n",
      "[Epoch 004 Training]\tCross-Entropy Loss:\t0.0339\n",
      "[Epoch 004 Validation]\tAverage F1 Score:\t1.0000\tAverage Jaccard/IoU:\t1.0000\n",
      "\n",
      "[Epoch 005 Training]\tCross-Entropy Loss:\t0.0316\n",
      "[Epoch 005 Validation]\tAverage F1 Score:\t1.0000\tAverage Jaccard/IoU:\t1.0000\n",
      "\n",
      "[Epoch 006 Training]\tCross-Entropy Loss:\t0.0295\n",
      "[Epoch 006 Validation]\tAverage F1 Score:\t1.0000\tAverage Jaccard/IoU:\t1.0000\n",
      "\n",
      "[Epoch 007 Training]\tCross-Entropy Loss:\t0.0277\n",
      "[Epoch 007 Validation]\tAverage F1 Score:\t1.0000\tAverage Jaccard/IoU:\t1.0000\n",
      "\n",
      "[Epoch 008 Training]\tCross-Entropy Loss:\t0.0260\n",
      "[Epoch 008 Validation]\tAverage F1 Score:\t1.0000\tAverage Jaccard/IoU:\t1.0000\n",
      "\n",
      "[Epoch 009 Training]\tCross-Entropy Loss:\t0.0246\n",
      "[Epoch 009 Validation]\tAverage F1 Score:\t1.0000\tAverage Jaccard/IoU:\t1.0000\n",
      "\n",
      "[Epoch 010 Training]\tCross-Entropy Loss:\t0.0234\n",
      "[Epoch 010 Validation]\tAverage F1 Score:\t1.0000\tAverage Jaccard/IoU:\t1.0000\n",
      "\n",
      "[Epoch 011 Training]\tCross-Entropy Loss:\t0.0223\n",
      "[Epoch 011 Validation]\tAverage F1 Score:\t1.0000\tAverage Jaccard/IoU:\t1.0000\n",
      "\n",
      "[Epoch 012 Training]\tCross-Entropy Loss:\t0.0215\n",
      "[Epoch 012 Validation]\tAverage F1 Score:\t1.0000\tAverage Jaccard/IoU:\t1.0000\n",
      "\n",
      "[Epoch 013 Training]\tCross-Entropy Loss:\t0.0209\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/project/6052161/mattlk/workplace/CompNet/train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(net, dataloader, epoch, device, use_dice_loss, experiment, batch_freq, epoch_freq, threshold, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mdice_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_mean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdice_mean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m#         all_f1 = torch.stack((all_f1, dice)) if i == 0 else dice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6052161/mattlk/workplace/CompNet/metrics.py\u001b[0m in \u001b[0;36mdice_score\u001b[0;34m(outputs, labels, smooth)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     intersect = torch.dot(outputs.contiguous().view(-1),\n\u001b[0;32m---> 16\u001b[0;31m                           labels.contiguous().view(-1))\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0munion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mintersect\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0munion\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# with experiment.train():\n",
    "num_accumulated_steps = 128 // params['batch_size']\n",
    "\n",
    "print(f'Number of training images:\\t{num_train}\\nNumber of validation images:\\t{num_val}')\n",
    "for epoch in range(params['epochs']):\n",
    "\n",
    "    unet, running_loss = train_one_epoch(unet, train_dataloader, optimizer,\n",
    "                                         criterion, \n",
    "                                         num_accumulated_steps=num_accumulated_steps, \n",
    "                                         **params)\n",
    "\n",
    "    if params['use_dice_loss']:\n",
    "        print(f'[Epoch {epoch+1:03d} Training]\\tDice Loss:\\t\\t{running_loss:.4f}')\n",
    "    else:\n",
    "        print(f'[Epoch {epoch+1:03d} Training]\\tCross-Entropy Loss:\\t{running_loss:.4f}')\n",
    "#     experiment.log_metric(\"Running Loss\", running_loss, epoch=epoch, step=epoch, include_context=False)\n",
    "\n",
    "    f1_mean, jaccard_mean = validate(unet, val_dataloader, epoch, device,\n",
    "#                                      experiment=experiment, batch_freq=25,\n",
    "                                     experiment=None, batch_freq=25,\n",
    "                                     epoch_freq=25, **params)\n",
    "\n",
    "    if params['scheduler'] == 'ReduceLROnPlateau':\n",
    "        scheduler.step(f1_mean)\n",
    "    else:\n",
    "        scheduler.step()\n",
    "    print(f'[Epoch {epoch+1:03d} Validation]\\tAverage F1 Score:\\t{f1_mean:.4f}\\tAverage Jaccard/IoU:\\t{jaccard_mean:.4f}\\n')\n",
    "\n",
    "#     experiment.log_metric('Validation Average F1 Score', f1_mean,\n",
    "#                           epoch=epoch, include_context=False)\n",
    "#     experiment.log_metric('Validation Average Jaccard/IoU', jaccard_mean,\n",
    "#                           epoch=epoch, include_context=False)\n",
    "\n",
    "# torch.save(unet.state_dict(), 'unet.pth')\n",
    "# experiment.log_asset('unet.pth', copy_to_tmp=False)\n",
    "# experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('CompNet': conda)",
   "language": "python",
   "name": "python361064bitcompnetconda53738006ed9d4ff8b58cccf30ed5af95"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}