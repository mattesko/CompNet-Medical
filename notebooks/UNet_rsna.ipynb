{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "\n",
    "from comet_ml import Experiment\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from src.dataset import Chaos2DSegmentationDataset, NormalizeInstance, get_image_pair_filepaths\n",
    "from src.models import UNet\n",
    "from src.metrics import dice_loss, dice_score\n",
    "from src.utils import create_canvas\n",
    "from src.train import train_one_epoch, validate\n",
    "from src.config import directories\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 # 0: off, 2: on for all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the below directory depending on where the CHAOS dataset is stored\n",
    "data_dir = directories['rsna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Lambda(lambda x: x.unsqueeze(0)),\n",
    "            transforms.Lambda(lambda x: F.interpolate(x, size=self.size)),\n",
    "            transforms.Lambda(lambda x: x.squeeze(0))\n",
    "        ])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unet.unet_model.UNet"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size\": 16,\n",
    "    \"split_train_val\": 0.8,\n",
    "    \"epochs\": 125,\n",
    "    \"use_dice_loss\": False,\n",
    "    \"cache\": True,\n",
    "    \"random_seed\": 42,\n",
    "    \"shuffle_data\": True,\n",
    "    \"scheduler\": \"StepLR\",\n",
    "    \"step_size\": 15,\n",
    "    \"gamma\": 0.75,\n",
    "    \"threshold\": 0.75\n",
    "}\n",
    "\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if is_cuda_available else \"cpu\")\n",
    "input_images_dtype = torch.double\n",
    "targets_dtype = torch.long\n",
    "\n",
    "cache_input_transform = transforms.Compose([\n",
    "    NormalizeInstance(mean=1.0),\n",
    "    transforms.Lambda(lambda x: x.astype(np.float32)),\n",
    "    transforms.ToTensor(),\n",
    "    Resize((224, 224)),\n",
    "])\n",
    "\n",
    "cache_gt_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    Resize((224, 224)),\n",
    "])\n",
    "\n",
    "input_transform = transforms.Compose([\n",
    "#     transforms.RandomAffine(degrees=5, shear=5),\n",
    "#     transforms.ToTensor()\n",
    "])\n",
    "\n",
    "gt_transform = transforms.Compose([\n",
    "#     transforms.RandomAffine(degrees=5, shear=5),\n",
    "#     transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x*255),\n",
    "    transforms.Lambda(lambda x: x.long()),\n",
    "])\n",
    "\n",
    "# Load data for training and validation\n",
    "image_pair_filepaths = get_image_pair_filepaths(data_dir)[:200]\n",
    "train_filepaths, val_filepaths = train_test_split(image_pair_filepaths,\n",
    "                                                  train_size=params['split_train_val'],\n",
    "                                                  random_state=params['random_seed'],\n",
    "                                                  shuffle=params[\"shuffle_data\"])\n",
    "# train_filepaths, val_filepaths = image_pair_filepaths, image_pair_filepaths\n",
    "\n",
    "train_dataset = Chaos2DSegmentationDataset(train_filepaths, input_transform=input_transform,\n",
    "                                           gt_transform=gt_transform, cache=params['cache'],\n",
    "                                           cache_input_transform=cache_input_transform,\n",
    "                                           cache_gt_transform=cache_gt_transform,\n",
    "                                           device=device)\n",
    "\n",
    "val_dataset = Chaos2DSegmentationDataset(val_filepaths, input_transform=input_transform,\n",
    "                                         gt_transform=gt_transform, cache=params['cache'],\n",
    "                                         cache_input_transform=cache_input_transform,\n",
    "                                         cache_gt_transform=cache_gt_transform,\n",
    "                                         device=device)\n",
    "\n",
    "num_train, num_val = len(train_dataset), len(val_dataset)\n",
    "params['num_samples'] = num_train + num_val\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=params['batch_size'])\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=params['batch_size'])\n",
    "\n",
    "# Instantiate model, optimizer, and criterion\n",
    "torch.cuda.empty_cache()\n",
    "unet = UNet(dice=params['use_dice_loss'])\n",
    "if is_cuda_available: unet = unet.to(device, dtype=input_images_dtype)\n",
    "\n",
    "optimizer = optim.Adam(unet.parameters(), lr=params['lr'])\n",
    "if params['scheduler'] == 'StepLR': \n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                          step_size=params['step_size'], gamma=params['gamma'])\n",
    "elif params['scheduler'] == 'ReduceLROnPlateau':\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# cross-entropy loss: weighting of negative vs positive pixels\n",
    "loss_weight = torch.DoubleTensor([0.01, 0.99])\n",
    "if is_cuda_available: loss_weight = loss_weight.to(device)\n",
    "criterion = dice_loss if params['use_dice_loss'] else CrossEntropyLoss(weight=loss_weight,\n",
    "                                                                       reduction='mean')\n",
    "\n",
    "experiment.log_parameters(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('CompNet': conda)",
   "language": "python",
   "name": "python361064bitcompnetconda53738006ed9d4ff8b58cccf30ed5af95"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}