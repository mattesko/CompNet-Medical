{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/project/6052161/mattlk/workplace/CompNet')\n",
    "import os\n",
    "# os.chdir('CompositionalNets/')\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "from comet_ml import Experiment\n",
    "from mlflow import log_metric, log_param, log_artifact\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from dataset import Chaos2DSegmentationDataset, NormalizeInstance, get_image_pair_filepaths\n",
    "from models import UNet\n",
    "from loss import dice as dice_loss\n",
    "%load_ext autoreload\n",
    "%autoreload 2 # 0: off, 2: on for all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the below directory depending on where the CHAOS dataset is stored\n",
    "data_dir = os.path.join('CompositionalNets', 'data', 'chaos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/matthew42/chaos-liver-segmentation/2b4d2a1e91b14653aba01a0d375ee809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(api_key=\"P5seMqEJjqZ8mDA7QYSuK3yUJ\",\n",
    "                        project_name=\"chaos-liver-segmentation\", \n",
    "                        workspace=\"matthew42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train U-Net on CHAOS for Liver Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 2,\n",
    "    \"split_train_val\": 0.8,\n",
    "    \"low_lr_epoch\": 80,\n",
    "    \"epochs\": 3,\n",
    "    \"use_dice_loss\": False\n",
    "}\n",
    "experiment.log_parameters(parameters)\n",
    "\n",
    "lr = parameters['lr']\n",
    "batch_size = parameters['batch_size']\n",
    "split_train_val = parameters['split_train_val']\n",
    "low_lr_epoch = parameters['low_lr_epoch']\n",
    "epochs = parameters['epochs']\n",
    "use_dice_loss = parameters['use_dice_loss']\n",
    "num_samples = 1000\n",
    "\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if is_cuda_available else \"cpu\")\n",
    "input_images_dtype = torch.double\n",
    "gt_images_dtype = torch.long\n",
    "cache_data = True\n",
    "\n",
    "input_transform = transforms.Compose([\n",
    "    NormalizeInstance(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load data for training and validation\n",
    "image_pair_filepaths = get_image_pair_filepaths(data_dir)\n",
    "train_filepaths = image_pair_filepaths[:int(len(image_pair_filepaths)*split_train_val)]\n",
    "val_filepaths = image_pair_filepaths[int(len(image_pair_filepaths)*split_train_val):]\n",
    "\n",
    "train_dataset = Chaos2DSegmentationDataset(train_filepaths, input_transform=input_transform, cache=cache_data, device=device)\n",
    "val_dataset = Chaos2DSegmentationDataset(val_filepaths, input_transform=input_transform, cache=cache_data, device=device)\n",
    "print(f'Number of training images: {len(train_dataset)}\\nNumber of validation images: {len(val_dataset)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Instantiate model, optimizer, and criterion\n",
    "torch.cuda.empty_cache()\n",
    "unet = UNet(dice=use_dice_loss)\n",
    "# unet = UNet(in_channels=1, out_channels=1, padding=0)\n",
    "if is_cuda_available: unet = unet.to(device, dtype=input_images_dtype)\n",
    "\n",
    "optimizer = optim.Adam(unet.parameters(), lr=lr)\n",
    "\n",
    "# cross-entropy loss: weighting of negative vs positive pixels\n",
    "loss_weight = torch.DoubleTensor([0.01, 0.99])\n",
    "if is_cuda_available: loss_weight = loss_weight.to(device)\n",
    "criterion = dice_loss if use_dice_loss else CrossEntropyLoss(weight=loss_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with experiment.train():\n",
    "    for epoch in tqdm(range(epochs), desc=f'Training {epochs} epochs'):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        unet.train()\n",
    "\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "\n",
    "            input_images, gt_images = data\n",
    "\n",
    "            if is_cuda_available:\n",
    "                input_images = input_images.to(device, dtype=input_images_dtype)\n",
    "                gt_images = gt_images.to(device, dtype=gt_images_dtype)\n",
    "\n",
    "    #         pdb.set_trace()\n",
    "            outputs = unet(input_images)\n",
    "\n",
    "            if use_dice_loss:\n",
    "                outputs = outputs[:,1,:,:].unsqueeze(dim=1)\n",
    "                loss = criterion(outputs, gt_images)\n",
    "            else:\n",
    "                gt_images = gt_images.squeeze(dim=1)\n",
    "                loss = criterion(outputs, gt_images)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            experiment.log_metric('Loss', loss.item(), step=i, epoch=epoch)\n",
    "        if use_dice_loss:\n",
    "            print(f'[Epoch {epoch+1:03d}] Training Dice Loss: {running_loss/(i+1):.4f}')\n",
    "        else:\n",
    "            print(f'[Epoch {epoch+1:03d}] Training Cross-Entropy Loss: {running_loss/(i+1):.4f}')\n",
    "        experiment.log_metric(f\"{'Dice' if use_dice_loss else 'Cross-Entryopy'} Running Loss\", running_loss, epoch=epoch)\n",
    "\n",
    "        unet.eval()\n",
    "        val_accuracy = 0.0\n",
    "        all_accuracy = []\n",
    "        all_dice = []\n",
    "        all_outputs = []\n",
    "\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            accuracy = 0.0\n",
    "            intersect = 0.0\n",
    "            union = 0.0\n",
    "\n",
    "            input_images, gt_images = data\n",
    "            if is_cuda_available:\n",
    "                input_images = input_images.to(device, dtype=input_images_dtype)\n",
    "                gt_images = gt_images.to(device, dtype=gt_images_dtype)\n",
    "            outputs = unet(input_images)\n",
    "\n",
    "            # log softmax into softmax\n",
    "            if not use_dice_loss: outputs = outputs.exp()\n",
    "\n",
    "            # round outputs to either 0 or 1\n",
    "            outputs = outputs[:, 1, :, :].unsqueeze(dim=1).round()\n",
    "\n",
    "            # accuracy\n",
    "            outputs, gt_images = outputs.data.cpu().numpy(), gt_images.data.cpu().numpy()\n",
    "            accuracy += (outputs == gt_images).sum() / float(outputs.size)\n",
    "\n",
    "            # dice\n",
    "            intersect += (outputs+gt_images==2).sum()\n",
    "            union += np.sum(outputs) + np.sum(gt_images)\n",
    "\n",
    "            all_accuracy.append(accuracy / float(i+1))\n",
    "            all_dice.append(1 - (2 * intersect + 1e-5) / (union + 1e-5))\n",
    "\n",
    "            all_outputs.extend([out.permute() for out in outputs])\n",
    "\n",
    "        print(f'[Epoch {epoch+1:03d}] Validation Accuracy: {np.mean(all_accuracy)}. Validation Dice Score: {np.mean(all_dice)}')\n",
    "\n",
    "        experiment.log_metrics({\n",
    "            'Validation Accuracy': np.mean(all_accuracy),\n",
    "            'Validation Dice Score': np.mean(all_dice)\n",
    "        }, epoch=epoch)\n",
    "experiment.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
